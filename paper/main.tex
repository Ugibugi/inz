\input{./defs/WAT.tex}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{blindtext}
\newcommand{\kk}[1]{\todo[color=cyan!40,inline]{KK: #1}}

\newcommand{\Leg}[3][]{\mleft(\frac{#2\mathstrut}{#3}\mright)_{\mkern-6mu#1}} 
\newcommand{\studia}{STACJONARNE STUDIA $I^\circ$}
\newcommand{\temat}{Projekt i implementacja systemu do generowania podpisów na podstawie zdjęć}
\newcommand{\odstep}{40mm}
\newcommand{\autor}{Radosław KOPIŃSKI}
\newcommand{\promotor}{dr inż. Karol ANTCZAK}
\newcommand{\data}{Warszawa 2021}
\newcommand{\kierunek}{Informatyka}
\newcommand{\specjalnosc}{Modelowanie i symulacja}
\newcommand{\zadania}{

\begin{enumerate}
    \item Przegląd metod uczenia głębokiego w kontekście przetwarzania obrazów
    \item Przygotowanie opisu algorytmu generowania podpisów na podstawie zdjęć
    \item Implementacja algorytmu
    \item Trening i testy modelu na zebranym zbiorze danych
\end{enumerate}
}

\newcommand{\quot}[1]{``#1''}
\newtheorem{theorem}{Twierdzenie}

\newtheorem{definition}{Definicja}
\newtheorem{cor}{Wniosek}
\newtheorem{ex}{Przykład}
\begin{document}

\inserttitlepage

\tableofcontents

\newpage

\addcontentsline{toc}{section}{Wstęp}
\section*{Wstęp}
Celem tej pracy dyplomowej jest stworzenie systemu opartego o uczenie maszynowe, który będzie generował zrozumiałe dla człowieka podpisy dla obrazów. Zrealizowanie tego celu wymaga rozwiązania pewnych problemów pośrednich:
\begin{itemize}
	\item Wybór odpowiednich modeli przetwarzających obrazy, modele te powinny być w stanie operować z rozsądną wydajnością na komputerach klasy użytkowej. Oprócz tego należy także zaimplementować model generujący zdania.
	\item Zebranie oraz przygotowanie do użytku danych obrazkowych wymaganych do wytrenowania modelu. Dane w najlepszym przypadku powinny być odpowiednio liczne, posiadać obrazy o zróżnicowanej tematyce oraz posiadać więcej niż jeden podpis przyporządkowany do każdego obrazu.
	\item Opracowanie oraz wykorzystanie odpowiednich technik trenowania oraz oceniania zaimplementowanego modelu z wykorzystaniem wcześniej zebranych danych.
\end{itemize}

W pierwszym rozdziale zostaną przedstawione istniejące modele służące identyfikacji obiektów na obrazach. Modele z tej rodziny zostaną wykorzystane w systemie do wyciągnięcia informacji z zadanego obrazu oraz do wygenerowania stosownych podpisów. \par
W drugim rozdziale opisana zostanie zasada działania konstruowanego algorytmu. Wyszczególnione zostaną poszczególne komponenty oraz zostanie wyjaśniona ich rola w systemie. \par
W rozdziale trzecim zostanie zaprezentowana implementacja algorytmu przedstawionego w rozdziale drugim. Zostaną omówione biblioteki i narzędzia implementacji a także kwestie specyficzne dla implementacji. \par
W czwartym rozdziale omówione zostaną metody trenowania oraz oceny modelu. Podjęte zostaną próby polepszenia oceny modelu przez modyfikacje jego hiperparametrów. Przedstawione i zinterpretowane zostaną wyniki oceny. \par
W rozdziale piątym zostanie zawarte podsumowanie wykonanych zadań, ocena ich realizacji oraz zostaną wyciągnięte wnioski na temat osiągniętych wyników oraz sposobów ich otrzymania.

\newpage 
 
\section{Przegląd metod uczenia głębokiego w kontekście przetwarzania obrazów i generowania podpisów}
Zadanie generowania podpisów do obrazów składa się z dwóch etapów - rozpoznania obiektów oraz wygenerowania stosownych podpisów do nich. W poniższych sekcjach zostaną omówione modele i techniki wykorzystywane przy realizacji właśnie tych zadań
\subsection{Detekcja obiektów}
Głównym celem przetwarzania obrazów przez sieci neuronowe jest wyodrębnienie zbioru pewnych informacji istotnych dla użytkownika od informacji redundantnych oraz nieistotnych. Najczęściej przez informacje istotne rozumie się detekcję występujących obiektów oraz ich pozycję na obrazie, zwykle w postaci prostokąta (bounding box) oraz prawdopodobieństwa wykrycia obiektu w danym prostokącie.
\subsubsection{Neuronowe sieci konwolucyjne (CNN)}
Podstawowym narzędziem budowy modeli przetwarzających obrazy jest sieć konwolucyjna. O ile obrazy o małej rozdzielczości można przetwarzać stosując warstwy podłączone w pełni to ze względu na to że ilość parametrów rośnie $O(n^4)$ w stosunku do boku obrazu, trenowanie takich modeli szybko staje się nieopłacalne.

Problem ten rozwiązuje sieć konwolucyjna która do każdego neuronu podłącza tylko mały lokalny obszar obrazu o stałej wielkości. Sprawia to że ilość parametrów drastycznie się zmniejsza co skutkuje modelem łatwiejszym do trenowania a przez to mogącym przetwarzać większe obrazy. Podejście takie zostało zainspirowane badaniami nad aktywnością mózgu zwierzęcia podczas podawania prostych sygnałów wizualnych.\cite{CNN-cat}
\paragraph{Opis działania}
\subparagraph{Warstwa wejścia} 
Warstwą wejścia jest obraz o określonych rozmiarach i z brzegów dodanym marginesem  o określonej wartości (najczęściej 0). Wymiary tej warstwy oprócz wysokości i szerokości definiują także głębokość rozumianą jako kanały kolorów. \cite{CNN-expl}
\subparagraph{Warstwy konwolucyjne} 
Są one podstawowym składnikiem sieci konwolucyjnych. Wartość każdy neuronu w warstwie jest definiowana jako:

\begin{align*}
	o_i = \sum^C_c e^T(A^c_i \odot K^c)e
\end{align*}

Gdzie: $o_i$ - wartość neuronu wyjściowego, $C$ - ilość kanałów wejścia, $A^c_i$ - $i$-ta podmacierz $c$-tego kanału, $K^c$ - jądro dla $c$-tego kanału, $e$ - wektor jednostkowy, $\odot$ - produkt Hadamarda (mnożenie elementów)\cite{CNN-intro}.
Idee tej warstwy przedstawiono na rysunku \ref{conv-layer.png} \cite{CNN-intro}

\rysunek{conv-layer.png}{1}{Zasada działania warstwy konwolucyjnej}{https://arxiv.org/pdf/1511.08458.pdf}

\subparagraph{Warstwy wyboru}
Z angielskiego \quot{Pooling layer} - są to warstwy których głównym zadaniem jest redukcja wymiarów obrazu. Zasada działania jest podobna do Warstwy konwolucyjnej lecz zamiast macierzy jądra stosuje się prostszą funkcję redukującą wektor pikseli do jednego, na przykład poprzez wzięcie maksymalnej wartości z wektora (max-pooling) lub średniej (mean-pooling). W tej wartwie nie następuje żadne uczenie, ma ona za zadanie wyłącznie redukcje parametrów. \cite{CNN-intro}
\subparagraph{Warstwy porzucenia}
Nie są to warstwy specyficzne dla KSN lecz są często są w nich wykorzystywane. Warstwa ta jest podobna do zwykłej warstwy "pełnej" lecz przy każdym przejściu odłączany jest pewien określony wcześniej procent połączeń. Głównym celem tej warstwy jest zapobieganie przeuczeniu sieci. \cite{CNN-expl}

\subparagraph{Warstwa spłaszczania}
Warstwa ta jest zazwyczaj umieszczana przed warstwą wyjścia. Jej głównym celem jest reorganizacja neuronów ze struktury wielowymiarowej do struktury jednowymiarowej dla łatwiejszego obliczania wartości neuronów w warstwie wyjścia.\cite{CNN-expl}

\paragraph{Implementacje}
\subparagraph{AlexNet}
Jedna z najpopularniejszych implementacji algorytmu CNN. Model ten wygrał w konkursie ImageNet 2012 czym zwrócił uwagę świata informatycznego na zastosowanie sieci konwolucyjnych.
Sieć ta zawiera 5 warstw konwolucyjnych, 2 warstwy 50\% odrzucenia oraz 1000 neuronów na wyjściu z czego każdy indentyfikował jedną klasę obiektu znalezioną na zdjęciu, nie była podawana pozycja obiektu, był on tylko identyfikowany. Do trenowania modelu zastosowano także różne techniki rozszerzające zbiór danych treningowych, na przykład odbicia lustrzane. \cite{AlexNet} \cite{ORdum-2}

\rysunek{alex-net.png}{1}{Schemat struktury AlexNet wraz z wizualizacją warstw}{http://vision03.csail.mit.edu/cnn_art/index.html}

\subparagraph{Overfeat}
Overfeat jest połączeniem sieci klasyfikatora CNN wraz z regresorem mającym wyznaczyć pozycję obiektu. Najpierw trenuje się klasyfikator, następnie trenuje się regresor który stosuje klasyfikator na wybranych segmentach obrazu, budując mapę aktywacji i na jej podstawie określa bounding box (Rysunek \ref{overfeat-reg.png}). \cite{Overfeat} \cite{ORdum-2}

\rysunek{overfeat-reg.png}{.5}{Ilustracja działania regresora w modelu Overfeat.}{http://vision.stanford.edu/teaching/cs231b_spring1415/slides/overfeat_eric.pdf}

\subsubsection{Obszarowe neurononwe sieci konwolucyjne (R-CNN)}

\paragraph{R-CNN}
Obszarowe sieci neuronowe dzielą swoje działanie na 2 etapy: Propozycji obszarów oraz Detekcji klasy. Te dwa zadania realizowane są przez 2 oddzielne modele co powoduje względnie wolne działanie modelu. Model zaczyna pracę od wygenerowania pewnych obszarów co do których mamy podejrzenie ze może tam znajdować się obiekt należący do wykrywanych klas. Proces ten jest realizowany przez algorytm szukania selektywnego, gdzie obraz dzielony jest na obszary które następnie są ze sobą łączone ze względu na swoje podobieństwo i sąsiedztwo.\cite{ORdum-1}  Następnie regiony te są przekrztałcane do wymiarów warstwy wejścia do modelu zewnętrznego modelu CNN a następnie do modelu CNN który jest już trenowany przez nas. Na sam koniec ostateczniej klasyfikacji dokonuje model SVM. \cite{ORdum-3}

\paragraph{Faster R-CNN}
Ten model jak nazwa wskazuje jest bardzo podobny do oryginalnego R-CNN lecz stosuje on pewne optymalizacje. Pierwszą z nich jest danie obrazu wejściowego do przetworzenia zewnętrznemu modelowi CNN i użycie warstwy wyjściowej tego modelu do proponowania obszarów potencjalnego wystąpienia obiektu. Drugą optymalizacją jest zastosowanie modelu uczenia maszynowego do proponowania obszarów zamiast algorytmu szukania selektywnego.\cite{ORdum-1} Trzecią z ważniejszych optymalizacji jest wprowadzenie wspólnych warstw dla modelu wykrywania obszarów oraz dla modelu klasyfikacji, modele te trenuje się wtedy przemiennie. \cite{ORdum-3}

\subsubsection{Modele \quot{szybkie}}
\paragraph{YOLO}
Sieć ta pomija etap rozpoznawania obszarów stosowany w sieciach typu R-CNN, zamiast tego obraz jest dzielony na równe bloki o stałej szerokości którym jest przyporządkowywana określona liczba prostokątów okalających $B$. Dla każdego bloku obliczane jest prawdopodobieństwo zawierania obiektu w jednym z przyporządkowanych prostokątów i jeżeli prawdopodobieństwo jest odpowiednio duże określana jest przewidywana klasa obiektu. Warstwa wyjściowa dla każdego bloku składa się  z $B$ piątek określających prostokąt okalający oraz prawdopodobieństwo wystąpienia obiektu oraz liście prawdopodobieństw wszystkich klas.\cite{ORdum-4} Dzięki znaczniemu uproszczeniu metody generowania prostokątów okalających model YOLO oferuje znaczny spadek czasu detekcji przy jednoczesnym nieznacznym spadku celności. \cite{YOLOnet} 
\subsection{Generacja zdań}
Drugą częścią w podpisywaniu obrazów jest generacja samego podpisu z danych o obiektach znajdujących się na obrazie wytworzonych przez model detekcyjny. Wymagane jest wygenerowanie pewnego ciągu słów ze statycznych danych. Do tej części zadania naturalnie nadają się rekursywne sieci neuronowe (RNN) które są wstanie zmieniać swoje wyjście ze względu na swój stan wewnętrzny a przez to są zdolne do generowania sekwencji.\cite{RNN-in-cg} W tym przypadku elementem ciągu będą słowa a ciągiem - całe zdanie.
\subsubsection{Rekursywne sieci neuronowe}
\paragraph{Zasada działania}
Wyjście standardowego neuronu jest zależne wyłącznie od wektora wag $W$ i wektora wejściowego $X$. W ogólnym przypadku można tą zależność określić równaniem\footnote{Tutaj i w dalszych równaniach pomijany jest element stały (tzw bias) w celu polepszeniu czytelności równań. Może on być zastąpiony dodaniem dodatkowej kolumny w macierzy wejścia o stałej wartości równej 1} 
\begin{align*}
    \label{eqn:basic-neuron}
    r = f(W,X)
\end{align*}
Gdzie $f$ jest dowolną funkcją. \cite[p.~5]{nn-basic}
Głównym elementem wprowadzanym przez neurony rekursywne jest zależność wartości wyjściowej od poprzednich wartości wyjścia. Zależność ta sprawia że nie można już interpretować wyjścia neuronu jako osobnej wartości lecz jako część pewnego ciągu którego elementami są kolejne aktywacje neuronu. \cite[p.~7]{LSTM-intro} Jeżeli zdefiniujemy stan neuronu jako $S$ wtedy możemy w ogólnym przypadku określić wyjście neuronu rekursywnego jako:
\begin{align*}
    \label{eqn:rnn-neuron}
    r_i =& G(S_i) \\
    S_i =& f(W,S_{i-1},r_{i-1},X_i)
\end{align*}
gdzie $G$ to funkcja aktywacji dobierana przez użytkownika.
Na rysunku \ref{canon-RNN.png} przedstawiono najprostszy neuron rekursywny gdzie funkcje $f$ i $G$ zostały zdefiniowane jako:
\begin{align*}
    \label{eqn:rnn-neuron-canon}
    f(W,S,r,X) = W^T_{s,r,x}\begin{bmatrix} S \\ r \\ X \end{bmatrix} \\
    G(S) = \tanh(S)
\end{align*}
gdzie $W$ jest rozumiane jako tensor wag.
\rysunek{canon-RNN.png}{1}{Schemat najprostszego neuronu rekursywnego}{https://arxiv.org/pdf/1808.03314.pdf}
\paragraph{Neurony pamięci długo-krótkotrwałej (LSTM)}
Mimo że dzięki swojej rekursywności neurony RNN mogą generować ciągi przedstawiają one jednak spore problemy podczas ich trenowania zwyczajowymi metodami propagacji wstecznej. Jeżeli generowane ciągi sa zbyt długie mogą wystąpić dwa zjawiska: eksplozja gradientu lub zanik gradientu. W przypadku pierwszego przypadku wagi mogą wachać się między tymi samymi wartościami i nie dążyć do żadnej wartości lub może nastąpić przepełnienie w jednostce obliczeniowej. W drugim przypadku wartości gradientu są tak małe że wytrenowanie sieci zajęło by nieopłacalną ilość czasu lub w ogóle nie było by możliwe z powodu ograniczonej precyzji kodowania liczb rzeczywistych w jednostce obliczeniowej. Efekty te spowodowane sa tym że przez rekursywność neuronu gradient jest zależny wykładniczo od obecnych wag oraz od zastosowanej funkcji aktywacji $G$ która jest zawsze mniejsza niż 1.\cite[p.~18]{LSTM-intro}

Jako rozwiązanie tych problemów został zaproponowany neuron LSTM. Podczas projektowania LSTM zauważono że wykładnicza zależność gradientu od wag wynika z faktu iż wyjście neuronu $r$ zależy bezpośrednio od obecnego stanu neuronu $S$, wprowadzono więc dodatkowe parametry których zadaniem jest kontrolować wkład każdego z elementów do stanu oraz wyjścia neuronu.\cite[p.~22,23]{LSTM-intro} Elementy te zdefiniowane są następująco:
\begin{equation*}
    \label{eqn:lstm-neuron}
\begin{split} 
   	S_i &= \begin{bmatrix} g^s_i & g^u_i \end{bmatrix} \begin{bmatrix} S_{i-1} \\ u_i\end{bmatrix} \\
   	u_i &= G_d(W^T_{r,x}\begin{bmatrix}v_{i-1} \\ x_i \end{bmatrix} ) \\
   	v_i &= r_ig^r_i
\end{split}
\quad\quad\quad\quad
\begin{split}
   	g^s_i &=G_c( W^T_{s_{x,s,v}} \begin{bmatrix} x_i \\ s_{i-1} \\ v_{i-1} \end{bmatrix}) \\
   	g^u_i &=  G_c(W^T_{u_{x,s,v}} \begin{bmatrix} x_i \\ s_{i-1} \\ v_{i-1} \end{bmatrix}) \\
   	g^r_i &=   G_c(W^T_{r_{x,s,v}} \begin{bmatrix} x_i \\ s_i \\ v_{i-1} \end{bmatrix})
\end{split}
\quad\quad\quad\quad
\begin{split}
   G_d(x) &= \tanh(x) \\
   G_c(x) &= \frac{1}{1+e^{-x}}
\end{split}
\end{equation*}
Dzięki zastosowaniu w neuronie współczynników  regulujących $g^s_i ,g^r_i, g^u_i$ podczas treningu neuronu LSTM nie pojawia się efekt zanikającego gradientu, nadal jednak może wystąpić gradient eksplodujący, w tym przypadku przekształca się gradient tak żeby zawsze był w określonym przedziale.\cite[p.~22,23]{LSTM-intro}
\rysunek{LSTM-schema.png}{1}{Schemat neuronu LSTM}{https://arxiv.org/pdf/1808.03314.pdf}

\subsubsection{Kodowanie słów (Word Embedding)}
Żeby móc przetwarzać słowa w sieciach neuronowych trzeba je uprzednio odpowiednio przekształcić do formy wektora liczb który łatwo poddaje się metodom uczenia maszynowego. Są dwie metody zrealizowania tego zadania: Model Skip-gram oraz model CBOW.
\paragraph{CBOW}
Model przyjmuje na wejście $C$ słów które są przypisane wektorom liczbowym za pomocą kodowania \quot{1 z n}. Zbiór słów dobieranych na wejście jest związany z kolejnością wysntępowania w tekscie co tworzy swoisty kontekst występowania słowa. Na wyjściu zaś znajduje się jeden wektor o długości równej wielkości zbioru słów, a wartości tego wektora stanowią prawdopodobieństwo występowania słów w tym kontekście. Pomiędzy warstwami wejścia i wyjścia znajduje sie jedna warstwa ukryta o długości wynikowego kodowania słów. Metoda ta opiera się na transporcie danych z o wiele większej warstwy wejściowej przez małą warstwę ukrytą do warstwy wyjściowej. Jeżeli model zostanie dobrze wytrenowany (prawdopodobieństwa słów a warstwie wyjściowej będą odpowiadały rzeczywistym prawdopodobieństwom w warstwie wejściowej) wtedy oznacza to że model \quot{znalazł} sposób na zakodowanie informacji o słowie oraz jego kontekście do o wiele mniejszego wektora. Z tak wygenerowanego enkodera możemy dalej korzystać w sieciach neuronowych. \cite[p.~1,3]{word-embed}
\rysunek{CBOW.png}{1}{Schemat modelu CBOW}{https://arxiv.org/pdf/1808.03314.pdf}
\paragraph{Skip-gram}
Model ten działa podobnie do modelu CBOW lecz w odwrotną stronę - warstwa wejściowa zawiera jedno słowo (także zakodowane sposobem \quot{1 z n}), warstwa wyjściowa zaś zawiera $C$ rozkładów prawdopodobieństwa dla słów które mogą znaleźć się w kontekście słowa wejściowego. Wagi warstwy ukrytej także w tym przypadku reprezentują pewne kodowanie słów zachowujące ich kontekst.

\section{Opis algorytmu generowania podpisów}
\subsection{Zastosowane modele}
\subsection{Opis algorytmu}
\subsubsection{Przetwarzanie obrazu}
\subsubsection{Przetwarzanie słownika}
\subsubsection{Synteza wyniku}
\section{Implementacja modelu}
\subsection{Użyte narzędzia}
\begin{description}
\item[Python] Jest to dynamicznie typowany język skryptowy popularny w zastosowaniach sztucznej inteligencji. Charakteryzuje się on 
\item[Tensorflow]
\item[Keras]
\end{descripton}
\subsection{Moduł ładowania danych}
\subsection{Moduł przetwarzania obrazu}
\subsection{Moduł kodowania słów}
\subsection{Moduł generacji słów}
\section{Trening i testy modelu}
\subsection{Zbiory danych}
\subsection{Trening modelu}
\subsection{Testy i ocena modelu}
\section{Podsumowanie}

\newpage
\TODO{Generowanie bibliografi za pomocą bibtex i formatowanie}
\begin{thebibliography}{}
	\addcontentsline{toc}{section}{\refname}
	\bibitem {CNN-cat}MLA style: Press release. NobelPrize.org. Nobel Media AB 2021. Tue. 15 Jun 2021. <https://www.nobelprize.org/prizes/medicine/1981/press-release/> 
	\bibitem {CNN-intro} https://arxiv.org/abs/1511.08458
	\bibitem {AlexNet} https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
	\bibitem {Overfeat} https://arxiv.org/pdf/1312.6229.pdf
	\bibitem {ORdum-4} https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html
	\bibitem {ORdum-3}https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html
	\bibitem {ORdum-2}https://lilianweng.github.io/lil-log/2017/12/15/object-recognition-for-dummies-part-2.html 
	\bibitem {ORdum-1} https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html
	\bibitem {CNN-expl} https://poloclub.github.io/cnn-explainer
	\bibitem {RNN-in-cg}https://arxiv.org/pdf/1708.02043.pdf
	\bibitem {YOLOnet} https://arxiv.org/pdf/1506.02640v5.pdf
	\bibitem {main-model}https://arxiv.org/pdf/1411.4555.pdf
	\bibitem {nn-basic}https://www.researchgate.net/publication/300873377_Recurrent_Neural_Networks
	\bibitem {LSTM-intro} https://arxiv.org/pdf/1808.03314.pdf
	\bibitem {word2vec} https://arxiv.org/pdf/1310.4546.pdf
	\bibitem {word-embed}https://arxiv.org/pdf/1411.2738.pdf
\end{document}